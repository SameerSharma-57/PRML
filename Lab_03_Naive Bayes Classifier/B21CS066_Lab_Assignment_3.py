# -*- coding: utf-8 -*-
"""B21CS066_lab_03_lab_assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a4BR7D0HSuo51-frOI57F3CeOqum7x0B

#LAB 3

##importing libraries
"""

from operator import imod
import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib.ticker import AutoMinorLocator
from matplotlib import gridspec
from cycler import cycler
import sklearn.naive_bayes as nb
from sklearn.metrics import roc_curve,roc_auc_score,plot_roc_curve


import matplotlib.pyplot as plt
from sklearn.preprocessing import normalize
from sklearn.model_selection import train_test_split as tts
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error as mse
from sklearn.metrics import accuracy_score as acc
from sklearn.model_selection import KFold
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import cross_val_score
from sklearn import tree
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from math import ceil

"""##Problem 01

###Part 1
"""

tit = pd.read_csv("/content/drive/MyDrive/PRML/LAB03/titanic.csv",usecols=['Fare',"Sex","Age","Embarked","Survived"])
tit

tit=tit.dropna()

tit['Age']=tit['Age'].astype(int)
tit=tit.drop(tit[tit['Age']<1].index)

tit

sns.catplot(x='Sex',hue='Survived',kind='count',data=tit)
total_men=len(tit[(tit['Sex']=='male')].index)
total_men_survived=len(tit[(tit['Sex']=='male')&(tit['Survived']==1)].index)
total_women=len(tit[(tit['Sex']=='female')].index)
total_women_survived=len(tit[(tit['Sex']=='female')&(tit['Survived']==1)].index)

# total_men_survived = np.where(((tit['Sex']=='male') and (tit['Survived']==1)).bool)
print((total_men_survived/total_men))
print(total_women_survived/total_women)

sns.violinplot(x ="Sex", y ="Age", hue ="Survived",data = tit, split = True)

sns.catplot(x='Embarked',hue='Survived',kind='count',data=tit)
total_S=len(tit[(tit['Embarked']=='S')].index)
total_S_survived=len(tit[(tit['Embarked']=='S')&(tit['Survived']==1)].index)
total_C=len(tit[(tit['Embarked']=='C')].index)
total_C_survived=len(tit[(tit['Embarked']=='C')&(tit['Survived']==1)].index)
total_Q=len(tit[(tit['Embarked']=='Q')].index)
total_Q_survived=len(tit[(tit['Embarked']=='Q')&(tit['Survived']==1)].index)

print(total_S_survived/total_S)
print(total_C_survived/total_C)
print(total_Q_survived/total_Q)

# sns.catplot(x='Pclass',hue='Survived',kind='count',data=tit)
# total_1=len(tit[(tit['Pclass']==1)].index)
# total_1_survived=len(tit[(tit['Pclass']==1)&(tit['Survived']==1)].index)
# total_2=len(tit[(tit['Pclass']==2)].index)
# total_2_survived=len(tit[(tit['Pclass']==2)&(tit['Survived']==1)].index)
# total_3=len(tit[(tit['Pclass']==3)].index)
# total_3_survived=len(tit[(tit['Pclass']==3)&(tit['Survived']==1)].index)

# print(total_1_survived/total_1)
# print(total_2_survived/total_2)
# print(total_3_survived/total_3)

lab_enc = LabelEncoder()
tit['Sex']=lab_enc.fit_transform(tit['Sex'])
tit['Embarked']=lab_enc.fit_transform(tit['Embarked'])
tit=tit.set_index(np.arange(len(tit)))

tit

dataplot = sns.heatmap(tit.drop(["Survived"],axis=1).corr(), cmap="YlGnBu", annot=True)

X=tit.drop("Survived",axis=1)
Y=tit["Survived"]
X_train,X_test,Y_train,Y_test=tts(X,Y,test_size=0.2,shuffle=True)


print(X_train.shape,X_test.shape)

X_train.set_index(np.arange(X_train.shape[0]),inplace=True)
X_test.set_index(np.arange(X_test.shape[0]),inplace=True)
Y_train.index=np.arange(len(Y_train))
Y_test.index=np.arange(len(Y_test))

"""###Part 2

Best naive bayes classifier for this dataset is gaussian naive bayes classifier
"""

for dataheader in ["Age","Fare"]:
  sns.distplot(X[dataheader])
  plt.show()

for func in [nb.GaussianNB,nb.MultinomialNB,nb.BernoulliNB,nb.CategoricalNB,nb.ComplementNB]:
  Bayes_model=func().fit(X_train,Y_train)
  print("mse for ",func,"is ",mse(Bayes_model.predict(X_test),Y_test))


nb_gauss = nb.GaussianNB().fit(X_train[["Age","Fare"]],Y_train)
nb_cat=nb.CategoricalNB().fit(X_train[["Sex","Embarked"]],Y_train)
gauss_probs = nb_gauss.predict_proba(X_test[["Age","Fare"]])
cat_probs=nb_cat.predict_proba(X_test[["Sex","Embarked"]])
total_y_probs = np.multiply(gauss_probs,cat_probs)
y_pred=np.zeros(len(total_y_probs))
for i in range(len(y_pred)):
  if(total_y_probs[i][1]>total_y_probs[i][0]):
    y_pred[i]=1
print("mse for mixed naive bayes classifier is ",mse(y_pred,Y_test))

"""###Part 3"""

final_bayes_model=nb.GaussianNB().fit(X_train,Y_train)
Y_pred=final_bayes_model.predict(X_test)
print(final_bayes_model.score(X_test,Y_test))

def confusion_matrix(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  out=np.zeros((2,2),dtype=int)
  for i in range(len(test_y)):
      out[test_y[i],pred_y[i]]+=1
  return out
def avg_accuracy(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm_log = confusion_matrix(test_y,pred_y)
  out = (cm_log[0,0]+cm_log[1,1])/(cm_log.sum())
  return out

def precision(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm = confusion_matrix(test_y,pred_y)
  out = cm[1,1]/(cm[1,1]+cm[0,1])
  return out

def recall(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm = confusion_matrix(test_y,pred_y)
  out = cm[1,1]/(cm[1,1]+cm[1,0])
  return out

def f1_score(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  p=precision(test_y,pred_y)
  r=recall(test_y,pred_y)
  out = 2/((1/p)+(1/r))
  return out
def class_accuracy(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm=confusion_matrix(test_y,pred_y)
  out = [(cm[0,0]/(cm[0,0]+cm[0,1])),(cm[1,1]/(cm[1,1]+cm[1,0]))]
  return out

def sensitivity(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm=confusion_matrix(test_y,pred_y)
  out = cm[1,1]/(cm[1,1]+cm[1,0])
  return out

def specificity(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm=confusion_matrix(test_y,pred_y)
  out = cm[0,0]/(cm[0,0]+cm[0,1])
  return out

print("accuracy score is",avg_accuracy(Y_test,Y_pred))
print("confusion matrix\n",confusion_matrix(Y_test,Y_pred))
print("Precision is ", precision(Y_test,Y_pred))
print("recall is ", recall(Y_test,Y_pred))
print("F1 score is ",f1_score(Y_test,Y_pred))
print("Class wise accuracy is",class_accuracy(Y_test,Y_pred))
print("Sensitivity is ",sensitivity(Y_test,Y_pred))
print("Specificity is ",specificity(Y_test,Y_pred))
print("roc curve")
plot_roc_curve(final_bayes_model,X_test,Y_test)

"""###Part 4"""

from sklearn.metrics._plot.confusion_matrix import confusion_matrix
temp_gauss_model=nb.GaussianNB()
cv=KFold(n_splits=5,random_state=42,shuffle=True)
scores = cross_val_score(temp_gauss_model, X, Y,cv=cv,n_jobs=-1)

print("mean score ",np.mean(scores))
print("variance ",np.var(scores))

y_pred_probs = final_bayes_model.predict_proba(X_test)
for i in range(len(y_pred_probs)):
  print(max(y_pred_probs[i]))

"""###Part 5

"""

sns.kdeplot(data=tit, x='Age', y='Fare', hue='Survived')
plt.show()
sns.kdeplot(data=tit,x='Age',y='Sex',hue='Survived')
plt.show()
sns.kdeplot(data=tit, x='Age', y='Embarked', hue='Survived')
plt.show()
sns.kdeplot(data=tit,x='Fare',y='Sex',hue='Survived')
plt.show()
sns.kdeplot(data=tit, x='Fare', y='Embarked', hue='Survived')
plt.show()

"""###Part 6"""

dec_clf = DecisionTreeClassifier().fit(X_train,Y_train)
print(dec_clf.score(X_test,Y_test))

temp_DTC_model=DecisionTreeClassifier()
cv=KFold(n_splits=5,random_state=42,shuffle=True)
scores_DTC = cross_val_score(temp_DTC_model, X, Y,cv=cv,n_jobs=-1)
print("Gaussian Naive Bayes Classifier")
print("mean score ",np.mean(scores))
print("variance ",np.var(scores))
print("\nDecision Tree Classifier")
print("mean score ",np.mean(scores_DTC))
print("variance ",np.var(scores_DTC))

"""##Problem 2

###Part 1
"""

df = pd.read_csv("/content/drive/MyDrive/PRML/LAB03/dataset (1).csv");
df

plt.rcParams['figure.figsize'] = [12, 5]
dataheaders=["Area","Perimeter","Compactness","Length of kernel","Width of kernel","Asymmetry coefficient","Length of kernel groove"]
for dataheader,i in zip(df.columns[:-1],range(len(dataheaders))):
  x1 = list(df[df['Y'] == 1][dataheader])
  x2 = list(df[df['Y'] == 2][dataheader])
  x3 = list(df[df['Y'] == 3][dataheader])

  
  colors=['blue', 'green', 'orange']
  names=[1,2,3]

  
  n,bins,patches=plt.hist([x1, x2, x3], color=colors,bins=7, label=names, density=False)

  
  
  plt.legend()
  # define minor ticks and draw a grid with them
  minor_locator = AutoMinorLocator(2)
  plt.gca().xaxis.set_minor_locator(minor_locator)
  plt.grid(which='minor', color='white', lw = 0.5)
  # x ticks
  xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]
  xticks_labels = [ "{:.2f} to {:.2f}".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]
  plt.xticks(xticks, labels = xticks_labels)
  plt.title(dataheaders[i])
  plt.ylabel("count")
  plt.show()
  print('\n\n')

"""###Part 2"""

def class_probability(df,class_no,col):
  return (len(np.where(df[col]==class_no)[0]))/len(df[col])

for i in range(1,4):
  print("prior probability of class ",i,"is ",class_probability(df,i,'Y'))

"""###Part 3"""

def makeBins(df,no_of_bins):
  dis_df=df.copy()
  for col in df.columns[:-1]:

    min=df[col].min()
    dif=(df[col].max()-min)/no_of_bins
    for i in range(len(df[col])):
      dis_df[col][i]=ceil((df[col][i]-min)/dif)-1
  dis_df=dis_df.astype(int)
  return dis_df

no_of_bins=7
dis_df=makeBins(df,no_of_bins)
dis_df

"""###Part 4"""

def likelihood(df,col,y,bin_no):
  idx=np.where(df['Y']==y)
  count=0
  for i in idx[0]:
    if df[col][i]==bin_no:
      count+=1
  if(count==0):
    count=1/len(df.index)
  return count/len(idx[0])

def likelihoodForAllBins(df,col,y,total_bins):
  lhlist=np.zeros(total_bins)
  for i in range(total_bins):
    lhlist[i]=likelihood(df,col,y,i)
  return lhlist

n_classes=3
for i in range(1,n_classes+1):
  print("Class ",i)
  for dataheader in dis_df.columns[:-1]:
    print("Column: ",dataheader)
    print(likelihoodForAllBins(dis_df,dataheader,i,no_of_bins))
    print(sum(likelihoodForAllBins(dis_df,dataheader,i,no_of_bins)))
  print('\n\n')

"""###Part 5"""

for i in range(1,n_classes+1):
  print("Class ",i)
  plt.subplots_adjust(left=0.1,bottom=0.1,right=0.9,top=1.9,wspace=0.4,hspace=0.4)
  for j in range(len(dis_df.columns)-1):
    plt.subplot(3,3,j+1)
    # count_list=(likelihoodForAllBins(dis_df,dis_df.columns[j],i,no_of_bins)*(len(np.where())))
    plt.bar(np.arange(no_of_bins),((likelihoodForAllBins(dis_df,dis_df.columns[j],i,no_of_bins))*(len(np.where(dis_df['Y']==i)[0]))))
    # print(((likelihoodForAllBins(dis_df,dis_df.columns[j],i,no_of_bins))*(len(np.where(dis_df['Y']==i)))))
    plt.xlabel(dis_df.columns[j])
  plt.show()

"""###Part 6

"""

training_data,testing_data=tts(dis_df,test_size=0.2,shuffle=True)
training_data=training_data.set_index(np.arange(training_data.shape[0]))
testing_data=testing_data.set_index(np.arange(testing_data.shape[0]))

def posterior_probability(df,sample,class_no):
  total_likelihood=1
  
  for i in range(len(df.columns)-1):
    
    total_likelihood*=likelihood(df,df.columns[i],class_no,sample[i])
  # if(total_likelihood==0):
  #     total_likelihood=(1/len(df.index))**7
  
  posterior=total_likelihood*class_probability(df,class_no,df.columns[-1])
  return posterior

def normalized_posterior_probability(df,sample,n_classes):
  out=np.zeros(n_classes)
  # print(1)
  for i in range(1,n_classes+1):
    out[i-1]=posterior_probability(df,sample,i)
  sm_of_all_pp=sum(out)
  out=out/sm_of_all_pp
  
  return list(out)

# x_axis=np.arange(len(df.index),dtype=int)
# # print(x_axis)

colors=['r','y','b']
# print(testing_data.columns[2])
for i in range(len(testing_data.index)):
  
  pp=normalized_posterior_probability(training_data,list(testing_data.iloc[i,:-1]),3)
  for j in range(3):
    plt.scatter(i,pp[j],color=colors[j])
plt.legend(['Class 1','Class 2','Class 3'],loc="best")
  # print(list(testing_data.iloc[i,:-1]))
# print(training_data)
# print(type(training_data),type(dis_df),type(testing_data))

def posterior_probability(df,sample,class_no):
  total_likelihood=1
  
  for i in range(len(df.columns)-1):
    
    total_likelihood*=likelihood(df,df.columns[i],class_no,sample[i])
  # if(total_likelihood==0):
  #   total_likelihood=(1/len(df.index))**7
  posterior=total_likelihood*class_probability(df,class_no,df.columns[-1])
  return posterior

def normalized_posterior_probability(df,sample,n_classes):
  out=np.zeros(n_classes)
  # print(1)
  for i in range(1,n_classes+1):
    out[i-1]=posterior_probability(df,sample,i)
  sm_of_all_pp=sum(out)
  out=out/sm_of_all_pp
  
  return list(out)

# x_axis=np.arange(len(df.index),dtype=int)
# # print(x_axis)

colors=['r','y','b']
# print(testing_data.columns[2])
for i in range(len(dis_df.index)):
  
  pp=normalized_posterior_probability(dis_df,list(dis_df.iloc[i,:-1]),3)
  for j in range(3):
    plt.scatter(i,pp[j],color=colors[j])
plt.legend(['Class 1','Class 2','Class 3'],loc="best")
  # print(list(testing_data.iloc[i,:-1]))
# print(training_data)
# print(type(training_data),type(dis_df),type(testing_data))