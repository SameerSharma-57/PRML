# -*- coding: utf-8 -*-
"""B21CS066_lab_assignment_6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p77lHGopZSPktX8SKoDW4qXD-KcfTjaS

#importing libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.model_selection import train_test_split as tts
from sklearn.datasets import fetch_olivetti_faces
from sklearn.cluster import DBSCAN
import random
from sklearn.datasets import make_moons

"""#Problem 1

##Part 1
"""

df=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data',names=["ID","RI","Na","Mg","Al","Si","K","Ca","Ba","Fe","Type"])
df.head()

df.info()

sns.pairplot(data=df.drop('ID',axis=1),hue='Type',palette='hls',diag_kind=None)

X=df.drop(['ID','Type'],axis=1)
y=df['Type']
model=KMeans(n_clusters=7,random_state=42)
model.fit(X)

y_pred=model.predict(X)
new_df=df.copy()
new_df['Type']=y_pred
sns.pairplot(data=new_df.drop('ID',axis=1),hue='Type',palette='hls',diag_kind=None)

plt.rcParams['figure.figsize'] = [20, 10]
color=['red','blue','green','cyan','brown','yellow','orange']
centeroids=model.cluster_centers_

for header_x in range(len(X.columns)):
    for header_y in range(len(X.columns)):
        if(header_x==header_y):
            continue
        
        
        for i in range(7):
            idx=np.where(y_pred==i)[0]
            
            plt.scatter(X.iloc[idx,header_x],X.iloc[idx,header_y],color=color[i],label=i,s=10)
        plt.scatter(centeroids[:,header_x],centeroids[:,header_y],marker='X',s=30,color='black')
        plt.xlabel(X.columns[header_x])
        plt.ylabel(X.columns[header_y])
        plt.legend()
        plt.show()

"""##Part 2"""

Silhouette_scores=[]
for n_clusters in range(2,20):
    temp_model=KMeans(n_clusters=n_clusters,random_state=42)
    temp_model.fit(X)
    temp_y_pred=temp_model.predict(X)
    Silhouette_scores.append(silhouette_score(X,temp_y_pred))

# print(Silhouette_scores.argmax()+2)
plt.plot(range(2,20),Silhouette_scores)
argmx=Silhouette_scores.index(max(Silhouette_scores))
print(argmx+2)

"""##Part 3"""

distortions = []
K = range(1,10)
for k in K:
    kmeanModel = KMeans(n_clusters=k)
    kmeanModel.fit(X)
    distortions.append(kmeanModel.inertia_)
plt.plot(K,distortions,'bx-')

"""##Part 4

"""

X_train,X_test,y_train,y_test=tts(X,y,test_size=0.3,shuffle=True,random_state=42)

for k in [1,2,3]:
    knn_model=KNeighborsClassifier(n_neighbors=k)
    knn_model.fit(X_train,y_train)
    print('accuracy of single knn model on k=',k,'is',knn_model.score(X_test,y_test))

    knn=KNeighborsClassifier(n_neighbors=k)
    Bagg_clf=BaggingClassifier(estimator=knn,n_estimators=10)
    Bagg_clf.fit(X_train,y_train)
    print('accuracy of bagging classifier on k=',k,'is',Bagg_clf.score(X_test,y_test))

"""#Problem 2

##Part 1
"""

of = fetch_olivetti_faces()
df=pd.DataFrame(of.data)
df['Class']=of.target
df.isna().sum().sum()

X=df.drop('Class',axis=1)
y=df['Class']

class KMeans_Scratch:
    #initialized the classifier with no of clusters (k) and max no of iterations to perfrom
    def __init__(self,k,max_iter):
        self.k=k
        self.max_iter=max_iter

    #function to calculate euclidian distance between two points
    def __distance(self,x,y):
        distance=(x-y)**2
        distance=np.sqrt(distance.sum())
        return distance

    #function to assign clusters/ labels to the datapoints once the centroids are decided
    def __assign_clusters(self,X,centroids):
        clusters=[]
        for _ in range(self.k):
            clusters.append([])
        for x in X:
            # print(x)
            distance=[]
            for centroid in centroids:
                distance.append(self.__distance(x,centroid))
            clusters[distance.index(min(distance))].append(x)
        return clusters
            
    #function to update the centroids after each iteration
    def __update_centroids(self,clusters):
        means=[np.mean(cluster,axis=0) for cluster in clusters]
        return np.array(means)

    #function to train the classifier on a dataset X
    def train(self,X,ini_centroids):
        #initializing the centroids with ini_centroids got as parameter in input
        centroids=ini_centroids
        cnt=0
        for _ in range(self.max_iter):
            cnt+=1
            #assigning the datapoints to each cluster
            clusters=self.__assign_clusters(X,centroids)
            #calculating new centroids
            new_centroids=self.__update_centroids(clusters)
            #once we started getting same value of centroids twice, stop the iteration
            if(np.all(new_centroids==centroids)):
                # print(centroids,new_centroids)
                break
            centroids=new_centroids
        # print('cnt',cnt)
        self.cluster_centers_=centroids
        self.clusters=self.__assign_clusters(X,centroids)

    #function to predict label for a single sample. It will calculate the distance of x from each centroid and assign to one with which it has minimum distance
    def predict(self,x):
        distance=[]
        for centroid in self.cluster_centers_:
            distance.append(self.__distance(x,centroid))
        return distance.index(min(distance))

    #function to predict labels for dataset X consisting multiple samples.
    def test(self,X):
        preds=[]
        for x in X:
            preds.append(self.predict(x))
        return preds

    


idx=np.random.choice(400,40,replace=False)
# print(X)
init_centroids=X.iloc[idx,:].to_numpy()
clf=KMeans_Scratch(40,1000)
clf.train(X.to_numpy(),init_centroids)
clusters=clf.clusters
no_of_datapoints_in_cluster=[]
for cluster in clusters:
    no_of_datapoints_in_cluster.append(len(cluster))
print(no_of_datapoints_in_cluster)

idx=1
plt.rcParams['figure.figsize'] = [40, 10]
for x in clf.cluster_centers_:
    plt.subplot(4,10,idx)
    idx+=1
    plt.imshow(x.reshape(64,64))
plt.show()

plt.rcParams['figure.figsize'] = [40, 10]
for cluster in clf.clusters:
    for i in range(min(10,len(cluster))):
        plt.subplot(1,10,i+1)
        plt.imshow(cluster[i].reshape(64,64))
    plt.show()

init_cluster_means=[]
for i in range(40):
    idx=np.where(y==i)[0]
    init_cluster_means.append(random.choice(idx))
clf2=KMeans(n_clusters=40,init=X.iloc[init_cluster_means,:])
clf2.fit(X)

plt.rcParams['figure.figsize'] = [40, 10]
for idx,x in enumerate(clf2.cluster_centers_):
    plt.subplot(4,10,idx+1)
    plt.imshow(x.reshape(64,64))

y=clf2.labels_
clusters=[]
for i in np.unique(y):
    idx=np.where(y==i)[0]
    clusters.append(X.iloc[idx,:].to_numpy())

for cluster in clusters:
    print(len(cluster),end=' ')

for cluster in clusters:
    for i in range(min(10,len(cluster))):
        plt.subplot(1,min(10,len(cluster)),i+1)
        plt.imshow(cluster[i].reshape(64,64))
    plt.show()

def distance(x,y):
        distance=(x-y)**2
        return distance.sum()

def sse(clf,X):
    cluster_means=clf.cluster_centers_
    # cluster_means=clf.centroids
    sum=0
    
    for x in X:
        # print(x)
        y=clf.predict(x.reshape(1,-1))
        sum+=distance(x,cluster_means[y])
    return sum

print("sse for K means classifier built from scratch",sse(clf,X.to_numpy()))

print("sse for K means classifier from sklearn library",sse(clf2,X.to_numpy()))



"""#Problem 03"""

df=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00292/Wholesale%20customers%20data.csv')
df

df.info()

df=(df-df.min())/(df.max()-df.min())
df

sns.heatmap(df.corr(),annot=True)

plt.scatter(df['Detergents_Paper'],df['Grocery'])



dbscan_clf=DBSCAN().fit(df.to_numpy())
y=dbscan_clf.labels_
for i in np.unique(y):
    idx=np.where(y==i)[0]
    plt.scatter(df['Detergents_Paper'][idx],df['Grocery'][idx],label=i)
plt.legend()
plt.show()

idx=np.where(y==-1)[0]
plt.scatter(df['Detergents_Paper'][idx],df['Grocery'][idx])

k_means_clf=KMeans(n_clusters=7).fit(df.to_numpy())
y=k_means_clf.labels_
for i in np.unique(y):
    idx=np.where(y==i)[0]
    plt.scatter(df['Detergents_Paper'][idx],df['Grocery'][idx],label=i)
plt.legend()
plt.show()

moon_df=make_moons(n_samples=2000,noise=0.2)
moon_df

make_moon_df=pd.DataFrame(moon_df[0],columns=['X1','X2'])
make_moon_df['Y']=moon_df[1]
make_moon_df.info()

sns.scatterplot(data=make_moon_df,x='X1',y='X2',hue='Y')

X=make_moon_df.drop('Y',axis=1).to_numpy()
Y=make_moon_df['Y'].to_numpy()
Silhouette_scores=[]
K=np.arange(0.02,0.2,0.01)
# K=[]
for n_clusters in K:
    temp_model=DBSCAN(eps=n_clusters)
    temp_model.fit(X)
    temp_y_pred=temp_model.labels_
    # print(temp_y_pred)
    
    Silhouette_scores.append(silhouette_score(X,temp_y_pred))  
    

# print(K[Silhouette_scores.argmax()])
plt.plot(K,Silhouette_scores)
argmx=Silhouette_scores.index(max(Silhouette_scores))
print(K[argmx])

DBscan_moon_clf=DBSCAN(eps=0.08,min_samples=9).fit(X)
y=DBscan_moon_clf.labels_
for i in np.unique(y):
    idx=np.where(y==i)[0]
    plt.scatter(X[idx,0],X[idx,1],label=i)
plt.legend()
plt.show()

K_means_moon_clf=KMeans(n_clusters=2).fit(X)
y=K_means_moon_clf.labels_
for i in np.unique(y):
    idx=np.where(y==i)[0]
    plt.scatter(X[idx,0],X[idx,1],label=i)
plt.legend()
plt.show()

