# -*- coding: utf-8 -*-
"""B21CS066_lab_01_prml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QgOHim0dc0t4ZcZ67-Js-krztf5Y9p78

#Problem 1
"""

from google.colab import drive
drive.mount('/content/drive')

"""##Convert file data to list"""

import pandas as pd
url  = "https://drive.google.com/file/d/1tZ00rnowPhsEkaGpf6LYy7d830xqnhim/view?usp=share_link"
url='https://drive.google.com/uc?id=' + url.split('/')[-2]
dataset = pd.read_csv(url)
#dataset = pd.read_csv("https://drive.google.com/file/d/1tZ00rnowPhsEkaGpf6LYy7d830xqnhim/view?usp=share_link")
out = dataset.iloc[:,0]
out=out.values.tolist()
print(out);
print(type(out))

"""##Convert User Input to a Number"""

s = input();
out = int(s);
print(out);

"""##Convert String to Datetime in Python"""

from datetime import datetime

s = '01/10/23 16:07:26'

out = datetime.strptime(s, '%m/%d/%y %H:%M:%S')


print(out)

"""##How to call external commands in Python"""

# We can run external commands on local machine using os
# But on colab we can't do that
# we have to use ! sign to do this


out=!echo -e 'Sameer\nSharma'
out

"""##How to count the occurrences of a list item"""

my_list = [1,2,3,4,5,2,3,4,5,3,4,5,4,5,5]
count_5 = my_list.count(5)
print(count_5)

"""##How to flatten lists in Python"""

import numpy as np
my_list = [[1,2,3],[4,5,6]]
my_numpy_matrix = np.array(my_list);
my_flatten_numpy_matrix = my_numpy_matrix.flatten()
my_flatten_list = list(my_flatten_numpy_matrix)
print(my_flatten_list)

"""##How to merge dictionaries in Python"""

my_dict_01 = {'Rajasthan':'Jaipur','Haryana':'chandigarh'}
my_dict_02 = {'andhra pradesh':'hyderabad','uttar pradesh':'lucknow'}
my_dict_02.update(my_dict_01)
print(my_dict_02)

"""##Remove duplicate items from a list in Python"""

my_list = [1,2,3,4,5,2,3,4,5,3,4,5,4,5,5]
my_set = set(my_list)
print(list(my_set))

"""##Python script to check whether a given key already exists in a dictionary."""

my_dict = {'Rajasthan':'Jaipur','Haryana':'chandigarh'}
to_find_key = input()
if(to_find_key in my_dict):{
    print("Present")
}
else:
  {
    print("absent")
}

"""#Problem 2

"""

import numpy as np
matrix_01 = np.array([[1,2],[3,4]])
matrix_02 = np.array([[5,6],[7,8]])

# part (a)
print("displaying first row of first matrix")
print(matrix_01[0,:])

#part (b)
print("displaying second column of second matrix")
print(matrix_02[:,1])

#part (c)
print("displaying matrix multiplication of first and second matrix")
print(matrix_01@matrix_02)

#part (d)
print("displaying element wise multiplication of first and second matrix")
print(np.multiply(matrix_01,matrix_02))

#part (e)
for i in range(2):
  for j in range (2):
    print("displaying dot product of ",i,"th column of first matrix and ",j,"th column of second matrix")
    print(np.dot(matrix_01[:,i],matrix_02[:,j]))

"""#Problem 3

##defining type of measurement
"""

# model -> nominal
# type -> ordinal
# max price -> ratio
# airbags -> ordinal

"""##handle missing values"""

import pandas as pd
url  = "/content/drive/MyDrive/PRML/Lab-01/Copy of Cars93.csv"
dataset = pd.read_csv(url)
new_dataset=dataset;
for dataheader in dataset.columns:
  if(dataset[dataheader].dtype=='O'):
      new_dataset[dataheader].fillna('-')
  
  
new_dataset=dataset.fillna(0);
print(new_dataset.isnull().sum())
print(new_dataset)

"""##encoding the data"""

#encoding the data
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import normalize
from sklearn.model_selection import train_test_split as tts
lab_enc = LabelEncoder()
# lab_enc.fit_transform(new_datasetataset['Type']);
for dataheaders in ['Type','AirBags','DriveTrain','Origin']:
  new_dataset[dataheaders]=lab_enc.fit_transform(new_dataset[dataheaders])
print(new_dataset)

"""##noise reduction"""

#reducing noise


for dataheader in new_dataset.columns[2:]:
  for j in range(new_dataset[dataheader].size):
    try:
      new_dataset[dataheader][j]=new_dataset[dataheader][j].astype(float)
    except:
      new_dataset[dataheader][j]="0"
new_dataset

"""##normalize the data

"""

#normalize the data
for dataheaders in new_dataset.columns[2:]:
  new_dataset[dataheaders]=normalize([new_dataset[dataheaders]])[0]
print(new_dataset)

"""##spliting the data"""

training,temp=tts(new_dataset,test_size=0.3,shuffle=True)
validation,test=tts(temp,test_size=1/3,shuffle=True)

"""#Problem 4"""

from matplotlib import pyplot as plt

import numpy as np

def y1_x(x):
    return 5*x+4

def y2_x(x):
    return np.log(x)

def y3_x(x):
    return x*x


x=np.linspace(-10,10,100);
plt.plot(x,y1_x(x));
plt.show()

x=np.linspace(10,100,100)
plt.plot(x,y2_x(x));
plt.show()

x=np.linspace(-10,10,100)
plt.plot(x,y3_x(x))
plt.show()

x=np.array([0,1,2,3,4])
y4_x=np.array([2,3,4,5,6])
plt.scatter(x,y4_x)
plt.show()

"""#Problem 5

## Import the Necessary Python Libraries and Components
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split as tts
from sklearn.linear_model import LogisticRegression as LR
from sklearn.tree import DecisionTreeClassifier as DTC
from sklearn.metrics import confusion_matrix as cm
from sklearn.metrics import precision_score as ps
from sklearn.metrics import recall_score as rs
from sklearn.metrics import f1_score as f1s
from sklearn.metrics import accuracy_score as acc

"""## To Disable Convergence Warnings (For Custom Training)"""

from warnings import simplefilter
from sklearn.exceptions import ConvergenceWarning
simplefilter("ignore", category=ConvergenceWarning)

"""##1.) Input the Dataset"""

# Dataset Reference :- https://www.kaggle.com/uciml/breast-cancer-wisconsin-data

data = pd.read_csv("/content/drive/MyDrive/PRML/Lab-01/data.csv")
data

"""## 2.) Convert the String Labels into easily-interpretable Numerics"""

# Note :- There are many existing Encoders for converting String to Numeric Labels, but for convenience, we used Pandas.

condition_M = data.diagnosis == "M"
condition_B = data.diagnosis == "B"

data.loc[condition_M,"diagnosis"]=0
data.loc[condition_B,"diagnosis"]=1

data

"""## 3.) Converting Dataframe into Numpy Arrays (Features and Labels)"""

Y = data.diagnosis.to_numpy().astype('int')                                     # Labels

X_data = data.drop(columns=["id","diagnosis","Unnamed: 32"])
X = X_data.to_numpy()                                                           # Input Features

"""## 4.) Splitting the Dataset into Train and Test Portions"""

user_prompt = 0.3
user_enable = False

x_train,x_test,y_train,y_test = tts(X,Y,test_size=user_prompt,shuffle=user_enable)

"""## 5.) Model Training and Predicting"""

# Note :- Don't worry about the code snippet here, it is just to produce the predictions for the test data portion of each classifier

logistic_model = LR()
logistic_model.fit(x_train,y_train)
logistic_pred = logistic_model.predict(x_test)

decision_model = DTC()
decision_model.fit(x_train,y_train)
decision_pred = decision_model.predict(x_test)

"""## 6.) Evaluation Metrics (Inbulit v/s Scaratch)

### Confusion Matrix
"""

inbuilt_matrix_logistic = cm(y_test,logistic_pred)
inbuilt_matrix_decision = cm(y_test,decision_pred)
# print(type(logistic_pred))

print("Confusion Matrix for Logistic Regression-based Predictions =>")
print(inbuilt_matrix_logistic)
print("Confusion Matrix for Decision Tree-based Predictions =>")
print(inbuilt_matrix_decision)

def confusion_matrix(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  out=np.zeros((2,2),dtype=int)
  for i in range(len(test_y)):
      out[test_y[i],pred_y[i]]+=1
  return out


print("Confusion Matrix for Logistic Regression-based Predictions from scratch =>")
print(confusion_matrix(y_test,logistic_pred))
print("Confusion Matrix for Decision Tree-based Predictions from scratch =>")
print(confusion_matrix(y_test,decision_pred))

"""### Average Accuracy"""

inbuilt_acc_logistic = acc(y_test,logistic_pred)
inbuilt_acc_decision = acc(y_test,decision_pred)

print("Accuracy for Logistic Regression-based Predictions =>",str(inbuilt_acc_logistic*100)+"%")
print("Accuracy for Decision Tree-based Predictions =>",str(inbuilt_acc_decision*100)+"%")

def avg_accuracy(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm_log = confusion_matrix(test_y,pred_y)
  out = (cm_log[0,0]+cm_log[1,1])/(cm_log.sum())
  return out
print("Accuracy for Logistic Regression-based Predictions from scratch =>",str(avg_accuracy(y_test,logistic_pred)*100)+"%")
print("Accuracy for Decision Tree-based Predictions from scratch =>",str(avg_accuracy(y_test,decision_pred)*100)+"%")

"""### Precision"""

inbuilt_ps_logistic = ps(y_test,logistic_pred)
inbuilt_ps_decision = ps(y_test,decision_pred)

print("Precision for Logistic Regression-based Predictions =>",str(inbuilt_ps_logistic*100)+"%")
print("Precision for Decision Tree-based Predictions =>",str(inbuilt_ps_decision*100)+"%")

def precision(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm = confusion_matrix(test_y,pred_y)
  out = cm[1,1]/(cm[1,1]+cm[0,1])
  return out
print("Precision for Logistic Regression-based Predictions from scratch =>",str(precision(y_test,logistic_pred)*100)+"%")
print("Precision for Decision Tree-based Predictions from scratch =>",str(precision(y_test,decision_pred)*100)+"%")

"""### Recall"""

inbuilt_rs_logistic = rs(y_test,logistic_pred)
inbuilt_rs_decision = rs(y_test,decision_pred)

print("Recall for Logistic Regression-based Predictions =>",str(inbuilt_rs_logistic*100)+"%")
print("Recall for Decision Tree-based Predictions =>",str(inbuilt_rs_decision*100)+"%")

def recall(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm = confusion_matrix(test_y,pred_y)
  out = cm[1,1]/(cm[1,1]+cm[1,0])
  return out
print("Recall for Logistic Regression-based Predictions from scratch =>",str(recall(y_test,logistic_pred)*100)+"%")
print("Recall for Decision Tree-based Predictions from scratch =>",str(recall(y_test,decision_pred)*100)+"%")

"""### F-1 Score"""

inbuilt_f1s_logistic = f1s(y_test,logistic_pred)
inbuilt_f1s_decision = f1s(y_test,decision_pred)


print("F1-Score for Logistic Regression-based Predictions =>",str(inbuilt_f1s_logistic*100)+"%")
print("F1-Score for Decision Tree-based Predictions =>",str(inbuilt_f1s_decision*100)+"%")
def f1_score(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  p=precision(test_y,pred_y)
  r=recall(test_y,pred_y)
  out = 2/((1/p)+(1/r))
  return out
print("F1-Score for Logistic Regression-based Predictions from scratch =>",str(f1_score(y_test,logistic_pred)*100)+"%")
print("F1-Score for Decision Tree-based Predictions from scratch =>",str(f1_score(y_test,decision_pred)*100)+"%")

"""### Class-Wise Accuracy"""

def class_accuracy(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm=confusion_matrix(test_y,pred_y)
  out = ((cm[0,0]/(cm[0,0]+cm[0,1]))+(cm[1,1]/(cm[1,1]+cm[1,0])))*0.5
  return out
print("Class Accuracy for Logistic Regression-based Predictions from scratch =>",str(class_accuracy(y_test,logistic_pred)*100)+"%")
print("Class Accuracy for Decision Tree-based Predictions from scratch =>",str(class_accuracy(y_test,decision_pred)*100)+"%")

"""### Sensitivity"""

def sensitivity(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm=confusion_matrix(test_y,pred_y)
  out = cm[1,1]/(cm[1,1]+cm[1,0])
  return out
print("sensitivity for Logistic Regression-based Predictions from scratch =>",str(sensitivity(y_test,logistic_pred)*100)+"%")
print("sensitivity for Decision Tree-based Predictions from scratch =>",str(sensitivity(y_test,decision_pred)*100)+"%")

"""### Specificity"""

def specificity(test_y,pred_y):
  # Understand the Concept, write the code from scratch and remove "pass"
  cm=confusion_matrix(test_y,pred_y)
  out = cm[0,0]/(cm[0,0]+cm[0,1])
  return out
print("specificity for Logistic Regression-based Predictions from scratch =>",str(specificity(y_test,logistic_pred)*100)+"%")
print("specificity for Decision Tree-based Predictions from scratch =>",str(specificity(y_test,decision_pred)*100)+"%")